import pandas as pd
from datasets import Dataset
from transformers import AutoTokenizer
from pathlib import Path
from sklearn.model_selection import train_test_split

MODEL_NAME = "DeepPavlov/rubert-base-cased"

def main():
    base_dir = Path(__file__).resolve().parent.parent
    data_dir = base_dir / "data"
    csv_path = data_dir / "competency_500.csv"
    output_dir = data_dir / "tokenized_dataset"
    output_dir.mkdir(exist_ok=True)

    # 1Ô∏è‚É£ –ó–∞–≥—Ä—É–∂–∞–µ–º CSV
    df = pd.read_csv(csv_path)

    # 2Ô∏è‚É£ –£–±–∏—Ä–∞–µ–º –∫–ª–∞—Å—Å 0 (–Ω–µ—Ç –≤ –æ–±—É—á–µ–Ω–∏–∏)
    df = df[df["level"] != 0]

    # 3Ô∏è‚É£ –°–¥–≤–∏–≥–∞–µ–º —É—Ä–æ–≤–Ω–∏: 1‚Üí0, 2‚Üí1, 3‚Üí2
    df["level"] = df["level"] - 1

    # 4Ô∏è‚É£ –î–µ–ª–∏–º –Ω–∞ train/val (stratify –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ)
    train_df, val_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df["level"])

    # 5Ô∏è‚É£ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ Dataset
    train_dataset = Dataset.from_pandas(train_df)
    val_dataset = Dataset.from_pandas(val_df)

    # 6Ô∏è‚É£ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

    # 7Ô∏è‚É£ –§—É–Ω–∫—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏
    def tokenize(batch):
        return tokenizer(
            batch["resume_text"],
            batch["competency"],
            truncation=True,
            padding="max_length",
            max_length=256
        )

    # 8Ô∏è‚É£ –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    tokenized_train = train_dataset.map(tokenize, batched=True)
    tokenized_val = val_dataset.map(tokenize, batched=True)

    # 9Ô∏è‚É£ labels
    tokenized_train = tokenized_train.rename_column("level", "labels")
    tokenized_val = tokenized_val.rename_column("level", "labels")

    # üîü –§–æ—Ä–º–∞—Ç + —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    tokenized_train.set_format("torch", columns=["input_ids", "attention_mask", "labels"])
    tokenized_val.set_format("torch", columns=["input_ids", "attention_mask", "labels"])

    tokenized_train.save_to_disk(output_dir / "train")
    tokenized_val.save_to_disk(output_dir / "validation")

    print(f"–î–∞—Ç–∞—Å–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_dir}/train –∏ {output_dir}/validation")

if __name__ == "__main__":
    main()
